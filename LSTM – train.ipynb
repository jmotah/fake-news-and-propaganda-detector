{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import model_utils \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NORMALIZE AND CONCAT ALL DATASETS\n",
    "\n",
    "normalized_dfs = [\n",
    "    # Misinfo Dataset\n",
    "    model_utils.normalize_misinfo_dataset(\"datasets/misinfo-dataset/DataSet_Misinfo_FAKE.csv\"),\n",
    "    model_utils.normalize_misinfo_dataset(\"datasets/misinfo-dataset/DataSet_Misinfo_TRUE.csv\"),\n",
    "    model_utils.normalize_misinfo_dataset(\"datasets/misinfo-dataset/EXTRA_RussianPropagandaSubset.csv\"),\n",
    "    # Fake News Net Dataset\n",
    "    model_utils.normalize_fakenewsnet_dataset(\"datasets/fakenewsnet-dataset/gossipcop_fake.csv\"),\n",
    "    model_utils.normalize_fakenewsnet_dataset(\"datasets/fakenewsnet-dataset/gossipcop_real.csv\"),\n",
    "    model_utils.normalize_fakenewsnet_dataset(\"datasets/fakenewsnet-dataset/politifact_fake.csv\"),\n",
    "    model_utils.normalize_fakenewsnet_dataset(\"datasets/fakenewsnet-dataset/politifact_real.csv\"),\n",
    "    # Liar Dataset\n",
    "    model_utils.normalize_liar_dataset(\"datasets/liar-dataset/train.tsv\")\n",
    "]\n",
    "\n",
    "df = pd.concat(normalized_dfs, ignore_index=True)\n",
    "df = df.dropna(subset=[\"text\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Former Vice President Joe Biden was asked on Monday by Matt Lauer on NBC s  Today  to name something specific that Donald Trump has been  doing well. Well, that seems like a trick question since Trump has passed no major legislation and reaches across the aisle only to take shots at Democrats in his Twitter timeline during his morning rage-tweets, so Biden struggled to find something, anything, that Trump has done well since taking office. I think there s a number of things he s doing well. But even the things he s doing well, it s how he does them,  Biden said. It s more the tone of this administration that bothers me,  he continued. With all due respect, you haven t come up with one thing you think he s doing well,  Lauer said. Well, I think he married very well,  Biden joked.Although, Biden didn t mention which of Trump s three marriages he s speaking of. Trump s first marriage to Ivana ended after he had an affair with Marla Maples. Trump went on to marry Maples, then they divorced. Trump is currently married to Melania. All three of Trump s wives are former models. Trump is a former reality show star. But, in all instances, he did marry up, since there is no  down  that Trump hasn t hit yet.After struggling to come up with something, Biden eventually praised Trump s choice of keeping military personnel stationed in the Middle East that was there at the end of the Obama administration.Watch:\"What do you think Trump is doing well?\"\"I think he married very well.\"Joe Biden answers questions on @TODAYshow https://t.co/F6EKxHe64M  NBC News (@NBCNews) November 13, 2017In January, Biden had some advice for Trump.  Grow up, Donald,  Biden said of the 71-year-old man baby.  Grow up. Time to be an adult, you re president. You gotta do something, show us what you have,  Biden added.After speculation of Biden running for president in 2020, he admitted on Monday that he isn t ruling it out, but added he could not accept the nomination if it was given to him right now.Photo by Chip Somodevilla/Getty Images.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[100]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Tokenize (simple split)\n",
    "def tokenize(text):\n",
    "    return text.lower().split()\n",
    "\n",
    "# Build vocabulary\n",
    "counter = Counter()\n",
    "for text in train_df[\"text\"]:\n",
    "    counter.update(tokenize(text))\n",
    "\n",
    "vocab_size = 10000\n",
    "most_common = counter.most_common(vocab_size - 2)  # Reserve 0 for PAD, 1 for UNK\n",
    "word2idx = {\"<PAD>\": 0, \"<UNK>\": 1}\n",
    "word2idx.update({word: i + 2 for i, (word, _) in enumerate(most_common)})\n",
    "\n",
    "def encode(text):\n",
    "    return [word2idx.get(w, 1) for w in tokenize(text)[:300]]  # truncate at 300\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim=100, hidden_dim=64, pad_idx=0):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, 1)  # <-- 1 output for binary classification\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        embedded = self.embedding(x)\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(embedded, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        _, (hidden, _) = self.lstm(packed)\n",
    "        logits = self.fc(hidden[-1])\n",
    "        return logits.squeeze(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3: 100%|██████████| 2985/2985 [07:08<00:00,  6.97it/s, loss=0.581]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 0.5812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3: 100%|██████████| 2985/2985 [08:22<00:00,  5.94it/s, loss=0.442]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Loss = 0.4416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/3: 100%|██████████| 2985/2985 [08:17<00:00,  6.00it/s, loss=0.329]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Loss = 0.3294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "EPOCHS = 3\n",
    "\n",
    "class Dataset(Dataset):\n",
    "    def __init__(self, texts, labels):\n",
    "        self.data = [torch.tensor(encode(t)) for t in texts]\n",
    "        self.labels = torch.tensor(labels).float()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "\n",
    "def collate_fn(batch):\n",
    "    data, labels = zip(*batch)\n",
    "    lengths = torch.tensor([len(seq) for seq in data])\n",
    "    padded = nn.utils.rnn.pad_sequence(data, batch_first=True, padding_value=0)\n",
    "    return padded, lengths, torch.tensor(labels)\n",
    "\n",
    "train_dataset = Dataset(train_df[\"text\"].tolist(), train_df[\"label\"].tolist())\n",
    "test_dataset = Dataset(test_df[\"text\"].tolist(), test_df[\"label\"].tolist())\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, collate_fn=collate_fn)\n",
    "\n",
    "device = torch.device(\"mps\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = LSTMClassifier(vocab_size=len(word2idx), pad_idx=word2idx[\"<PAD>\"]).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "    for x, lengths, y in pbar:\n",
    "        x, lengths, y = x.to(device), lengths.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(x, lengths)\n",
    "        loss = criterion(logits, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        pbar.set_postfix(loss=total_loss / (pbar.n + 1))\n",
    "    print(f\"Epoch {epoch+1}: Loss = {total_loss/len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8762\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "all_preds, all_targets = [], []\n",
    "with torch.no_grad():\n",
    "    for x, lengths, y in test_loader:\n",
    "        x, lengths = x.to(device), lengths.to(device)\n",
    "        logits = model(x, lengths)\n",
    "        probs = torch.sigmoid(logits)\n",
    "        preds = (probs > 0.5).int().cpu().tolist()\n",
    "        all_preds.extend(preds)\n",
    "        all_targets.extend(y.int().tolist())\n",
    "\n",
    "acc = accuracy_score(all_targets, all_preds)\n",
    "print(f\"Test Accuracy: {acc:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
